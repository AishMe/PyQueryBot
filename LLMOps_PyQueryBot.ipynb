{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ya01bvwE2eQP",
        "oKeWkFzO2bAv",
        "W3kJqzdl3JTo",
        "yjhTaHNZ3ips",
        "llFzKRvh36mz",
        "sF1Pj2d64mP5",
        "_Z9g49Qe43h0",
        "zFnCK3tX4-xo",
        "jXMWLyA05gSG",
        "QmBgZFnJ1gmk"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Data Exploration for Tuning a Foundation Model**"
      ],
      "metadata": {
        "id": "ya01bvwE2eQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Project environment setup**\n",
        "\n",
        "* Load credentials and relevant Python Libraries.\n",
        "* If you were running this notebook locally, you would first install Vertex AI. `!pip install google-cloud-aiplatform`"
      ],
      "metadata": {
        "id": "oKeWkFzO2bAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from dotenv import load_dotenv\n",
        "except:\n",
        "  !pip install python-dotenv\n",
        "  !pip install google-cloud-aiplatform\n",
        "  from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "kx5QkcYK33Lk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install python-dotenv\n",
        "# !pip install google-cloud-aiplatform"
      ],
      "metadata": {
        "id": "jjcsbVchAzkz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "import base64\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.service_account import Credentials\n",
        "from google.cloud import bigquery\n",
        "\n",
        "def authenticate():\n",
        "    # Load .env\n",
        "    load_dotenv()\n",
        "\n",
        "    # Decode key and store in .JSON\n",
        "    SERVICE_ACCOUNT_KEY_STRING_B64 = os.getenv('SERVICE_ACCOUNT_KEY')\n",
        "    SERVICE_ACCOUNT_KEY_BYTES_B64 = SERVICE_ACCOUNT_KEY_STRING_B64.encode(\"ascii\")\n",
        "    SERVICE_ACCOUNT_KEY_STRING_BYTES = base64.b64decode(SERVICE_ACCOUNT_KEY_BYTES_B64)\n",
        "    SERVICE_ACCOUNT_KEY_STRING = SERVICE_ACCOUNT_KEY_STRING_BYTES.decode(\"ascii\")\n",
        "\n",
        "    SERVICE_ACCOUNT_KEY = json.loads(SERVICE_ACCOUNT_KEY_STRING)\n",
        "\n",
        "    # Create credentials based on key from service account\n",
        "    credentials = Credentials.from_service_account_info(\n",
        "        SERVICE_ACCOUNT_KEY,\n",
        "        scopes=['https://www.googleapis.com/auth/cloud-platform'])\n",
        "\n",
        "    if credentials.expired:\n",
        "        credentials.refresh(Request())\n",
        "\n",
        "    # Set project ID according to environment variable\n",
        "    PROJECT_ID = os.getenv('PROJECT_ID')\n",
        "\n",
        "    return credentials, PROJECT_ID\n",
        "\n",
        "# Authenticate and initialize BigQuery client\n",
        "credentials, PROJECT_ID = authenticate()\n",
        "bq_client = bigquery.Client(project=PROJECT_ID, credentials=credentials)"
      ],
      "metadata": {
        "id": "gQc1DcFoAuvM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/utils.py')"
      ],
      "metadata": {
        "id": "KA6PGSrrD01o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import utils\n",
        "# credentials, PROJECT_ID = authenticate()\n",
        "REGION = \"us-central1\""
      ],
      "metadata": {
        "id": "Axc8U0e323OD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Vertex AI SDK.\n",
        "The library helps to interact with the Vertex AI services in the cloud.\n",
        "Initialize it."
      ],
      "metadata": {
        "id": "vRXsC3ho243N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "\n",
        "vertexai.init(project = PROJECT_ID,\n",
        "              location = REGION,\n",
        "              credentials = credentials)"
      ],
      "metadata": {
        "id": "sfdPw_8g29fm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import BigQuery to use as your data warehouse.\n",
        "Initialize the client to start interacting with the data warehouse, send SQL and retrieve data into the notebook."
      ],
      "metadata": {
        "id": "1NRPX3Tt3CCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.cloud import bigquery\n",
        "# bq_client = bigquery.Client(project=PROJECT_ID, credentials = credentials)"
      ],
      "metadata": {
        "id": "WzD53iyJ3EMU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stack Overflow Public Dataset**\n",
        "\n",
        "* You will use Stack Overflow Data on BigQuery Public Datasets.\n",
        "The datasets include questions, answers and metadata related to Stack Overflow questions. Within this dataset, there are tables with data.\n",
        "\n",
        "* Create a SQL query."
      ],
      "metadata": {
        "id": "W3kJqzdl3JTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY_TABLES = \"\"\"\n",
        "SELECT\n",
        "  table_name\n",
        "FROM\n",
        "  `bigquery-public-data.stackoverflow.INFORMATION_SCHEMA.TABLES`\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ua8n2HUU3TpT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The query is asking to retrieve table_name of all the TABLES\n",
        "Use the client to send your SQL and retrieve the data (tables names)."
      ],
      "metadata": {
        "id": "8mRG0yO83WaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_job = bq_client.query(QUERY_TABLES)\n",
        "\n",
        "for row in query_job:\n",
        "    for value in row.values():\n",
        "        print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeNa7dYe3fck",
        "outputId": "3011a502-f22d-4eed-fbbe-91ad6e4d662a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "posts_answers\n",
            "users\n",
            "posts_orphaned_tag_wiki\n",
            "posts_tag_wiki\n",
            "stackoverflow_posts\n",
            "posts_questions\n",
            "comments\n",
            "posts_tag_wiki_excerpt\n",
            "posts_wiki_placeholder\n",
            "posts_privilege_wiki\n",
            "post_history\n",
            "badges\n",
            "post_links\n",
            "tags\n",
            "votes\n",
            "posts_moderator_nomination\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Retrieval**\n",
        "\n",
        "* You'll fetch some data from the data warehouse and store it in Pandas dataframe for visualization.\n",
        "\n",
        "* Select all columns from  posts_questions and put the LIMIT as 3."
      ],
      "metadata": {
        "id": "yjhTaHNZ3ips"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INSPECT_QUERY = \"\"\"\n",
        "SELECT\n",
        "    *\n",
        "FROM\n",
        "    `bigquery-public-data.stackoverflow.posts_questions`\n",
        "LIMIT 3\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qcdYR6xp3uRa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "query_job = bq_client.query(INSPECT_QUERY)"
      ],
      "metadata": {
        "id": "2s0dRZ6G3wgz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the results of the query --> create an arrow table (which is part of Apache Framework) --> which goes into a Pandas dataframe.\n",
        "This allows for data to be in a format which is easier to read and explore with Pandas."
      ],
      "metadata": {
        "id": "OUHPrtfQ3ysr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stack_overflow_df = query_job\\\n",
        "    .result()\\\n",
        "    .to_arrow()\\\n",
        "    .to_pandas()\n",
        "stack_overflow_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "U6zItksr3yR-",
        "outputId": "54446e32-8603-4a7a-8647-88683f6ee232"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                                      title  \\\n",
              "0  320268  Html.ActionLink doesnâ€™t render # properly   \n",
              "1  324003                        Primitive recursion   \n",
              "2  390605                         While vs. Do While   \n",
              "\n",
              "                                                body  accepted_answer_id  \\\n",
              "0  <p>When using Html.ActionLink passing a string...                 NaN   \n",
              "1  <p>how  will i define the function 'simplify' ...                 NaN   \n",
              "2  <p>I've seen both the blocks of code in use se...            390608.0   \n",
              "\n",
              "   answer_count  comment_count community_owned_date  \\\n",
              "0             0              0                  NaT   \n",
              "1             0              0                  NaT   \n",
              "2             0              0                  NaT   \n",
              "\n",
              "                     creation_date  favorite_count  \\\n",
              "0 2008-11-26 10:42:37.477000+00:00               0   \n",
              "1 2008-11-27 15:12:37.497000+00:00               0   \n",
              "2 2008-12-24 01:49:54.230000+00:00               2   \n",
              "\n",
              "                last_activity_date                   last_edit_date  \\\n",
              "0 2009-02-06 20:13:54.370000+00:00                              NaT   \n",
              "1 2012-09-25 19:54:40.597000+00:00 2012-09-25 19:54:40.597000+00:00   \n",
              "2 2008-12-24 03:08:55.897000+00:00                              NaT   \n",
              "\n",
              "  last_editor_display_name  last_editor_user_id owner_display_name  \\\n",
              "0                     None                  NaN              Paulo   \n",
              "1                   Marcin               1288.0               None   \n",
              "2                     None                  NaN          Unkwntech   \n",
              "\n",
              "   owner_user_id parent_id  post_type_id  score  \\\n",
              "0            NaN      None             1      0   \n",
              "1        41000.0      None             1      0   \n",
              "2          115.0      None             1      0   \n",
              "\n",
              "                                                tags  view_count  \n",
              "0                                        asp.net-mvc         390  \n",
              "1  haskell|lambda|functional-programming|lambda-c...         497  \n",
              "2                            language-agnostic|loops       11262  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0dd7256-541b-4737-9859-3e00cfa4a4bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>accepted_answer_id</th>\n",
              "      <th>answer_count</th>\n",
              "      <th>comment_count</th>\n",
              "      <th>community_owned_date</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>last_activity_date</th>\n",
              "      <th>last_edit_date</th>\n",
              "      <th>last_editor_display_name</th>\n",
              "      <th>last_editor_user_id</th>\n",
              "      <th>owner_display_name</th>\n",
              "      <th>owner_user_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>post_type_id</th>\n",
              "      <th>score</th>\n",
              "      <th>tags</th>\n",
              "      <th>view_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>320268</td>\n",
              "      <td>Html.ActionLink doesnâ€™t render # properly</td>\n",
              "      <td>&lt;p&gt;When using Html.ActionLink passing a string...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2008-11-26 10:42:37.477000+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>2009-02-06 20:13:54.370000+00:00</td>\n",
              "      <td>NaT</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Paulo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>asp.net-mvc</td>\n",
              "      <td>390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>324003</td>\n",
              "      <td>Primitive recursion</td>\n",
              "      <td>&lt;p&gt;how  will i define the function 'simplify' ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2008-11-27 15:12:37.497000+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-09-25 19:54:40.597000+00:00</td>\n",
              "      <td>2012-09-25 19:54:40.597000+00:00</td>\n",
              "      <td>Marcin</td>\n",
              "      <td>1288.0</td>\n",
              "      <td>None</td>\n",
              "      <td>41000.0</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>haskell|lambda|functional-programming|lambda-c...</td>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>390605</td>\n",
              "      <td>While vs. Do While</td>\n",
              "      <td>&lt;p&gt;I've seen both the blocks of code in use se...</td>\n",
              "      <td>390608.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2008-12-24 01:49:54.230000+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2008-12-24 03:08:55.897000+00:00</td>\n",
              "      <td>NaT</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unkwntech</td>\n",
              "      <td>115.0</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>language-agnostic|loops</td>\n",
              "      <td>11262</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0dd7256-541b-4737-9859-3e00cfa4a4bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e0dd7256-541b-4737-9859-3e00cfa4a4bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e0dd7256-541b-4737-9859-3e00cfa4a4bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-545d18a0-15bb-4f83-bf10-24fc5662667e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-545d18a0-15bb-4f83-bf10-24fc5662667e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-545d18a0-15bb-4f83-bf10-24fc5662667e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stack_overflow_df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dealing with Large Datasets**\n",
        "* Large datasets for LLMs often don't fit into memory.\n",
        "* Select all of the columns and rows of the table posts_questions."
      ],
      "metadata": {
        "id": "llFzKRvh36mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY_ALL = \"\"\"\n",
        "SELECT\n",
        "    *\n",
        "FROM\n",
        "    `bigquery-public-data.stackoverflow.posts_questions` q\n",
        "\"\"\"\n",
        "\n",
        "query_job = bq_client.query(QUERY_ALL)"
      ],
      "metadata": {
        "id": "lQ1Tgxe64C9v"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    stack_overflow_df = query_job\\\n",
        "    .result()\\\n",
        "    .to_arrow()\\\n",
        "    .to_pandas()\n",
        "except Exception as e:\n",
        "    print('The DataFrame is too large to load into memory.', e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPLOW5eB4Hmx",
        "outputId": "5e4a7e91-727d-4c55-b995-a3dd333431eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DataFrame is too large to load into memory. 403 GET https://bigquery.googleapis.com/bigquery/v2/projects/llmops-project-438807/queries/e29e11ca-5fdc-4a65-9539-ae3218e25fa8?maxResults=0&location=US&prettyPrint=false: Response too large to return. Consider specifying a destination table in your job configuration. For more details, see https://cloud.google.com/bigquery/troubleshooting-errors\n",
            "\n",
            "Location: US\n",
            "Job ID: e29e11ca-5fdc-4a65-9539-ae3218e25fa8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "* The data is too large to return, as it is not fitting into memory.\n",
        "* Joining Tables and Query Optimization\n",
        "* When working with (large) data, query optimizing is needed in order to save time and resources.\n",
        "* Select questions as input_text (column 1), answers as output_text (column 2).\n",
        "* Take the questions from posts_questions and answers from posts_answers.\n",
        "* Join the questions and their corresponding accepted answers based on their same unique ID.\n",
        "* Making sure the question is about Python, and that it has an answer. And the date the question was posted is on or after 2020-01-01\n",
        "* Limit as 10,000"
      ],
      "metadata": {
        "id": "AhgJIAKJ4Moj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY = \"\"\"\n",
        "SELECT\n",
        "    CONCAT(q.title, q.body) as input_text,\n",
        "    a.body AS output_text\n",
        "FROM\n",
        "    `bigquery-public-data.stackoverflow.posts_questions` q\n",
        "JOIN\n",
        "    `bigquery-public-data.stackoverflow.posts_answers` a\n",
        "ON\n",
        "    q.accepted_answer_id = a.id\n",
        "WHERE\n",
        "    q.accepted_answer_id IS NOT NULL AND\n",
        "    REGEXP_CONTAINS(q.tags, \"python\") AND\n",
        "    a.creation_date >= \"2020-01-01\"\n",
        "LIMIT\n",
        "    10000\n",
        "\"\"\"\n",
        "\n",
        "query_job = bq_client.query(QUERY)"
      ],
      "metadata": {
        "id": "3VSh3lQb4aH2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stack_overflow_df = query_job.result()\\\n",
        "                        .to_arrow()\\\n",
        "                        .to_pandas()\n",
        "\n",
        "stack_overflow_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "GDGCj2kh4ily",
        "outputId": "b8f370b6-6add-450d-e780-23c56b8cdfde"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          input_text  \\\n",
              "0  Turn PyCharm package back to a directory in Pr...   \n",
              "1  Pandas Select Rows from a dataframe with highe...   \n",
              "\n",
              "                                         output_text  \n",
              "0  <p>Right click the folder -&gt; Mark directory...  \n",
              "1  <p>use groupby and take the max</p>\\n<pre><cod...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14aff94c-b339-4567-9115-9a900a9334b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>output_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Turn PyCharm package back to a directory in Pr...</td>\n",
              "      <td>&lt;p&gt;Right click the folder -&amp;gt; Mark directory...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pandas Select Rows from a dataframe with highe...</td>\n",
              "      <td>&lt;p&gt;use groupby and take the max&lt;/p&gt;\\n&lt;pre&gt;&lt;cod...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14aff94c-b339-4567-9115-9a900a9334b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14aff94c-b339-4567-9115-9a900a9334b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14aff94c-b339-4567-9115-9a900a9334b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-77afc361-0b06-4217-ad9a-5818a4673074\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77afc361-0b06-4217-ad9a-5818a4673074')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-77afc361-0b06-4217-ad9a-5818a4673074 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stack_overflow_df",
              "summary": "{\n  \"name\": \"stack_overflow_df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"input_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"Discord.py and Webbrowser | How do I make the web browser open for only the author of the message?<pre><code>@client.command()\\nasync def open(ctx, pagelink):\\n    page = (pagelink)\\n    webbrowser.open(page, new=2)\\n    if pagelink == 'yt':\\n        page = ('https://www.youtube.com/')\\n        webbrowser.open(page, new=2)\\n        await ctx.send(f&quot;{page} opened, please check your web browser :&gt;&quot;)\\n    elif pagelink == 'reddit':\\n        page = (&quot;https://www.reddit.com/&quot;)\\n        webbrowser.open(page, new=2)\\n    elif pagelink == &quot;whatsapp&quot;:\\n        page = (&quot;https://web.whatsapp.com/&quot;)\\n        webbrowser.open(page, new=2)\\n    elif pagelink == &quot;pornhub&quot;:\\n        page = (&quot;pornhub.com&quot;)\\n        webbrowser.open(page, new=2)\\n</code></pre>\\n<p>Right now, this command only works for MY browser, how do I get it to work for everyone? Like open up the browser of the one using the command only?\\nFor example, my friend uses the command but it doesn't open anything for him, it only opens for me. Why??</p>\",\n          \"Reading text files into a python list of dictionary<p>I have a text file within it there are dictionaries in this format</p>\\n<pre><code>{'name':'Jack', 'age': 20}\\n{'name': 'Joseph', 'age': 13}\\n{'name':'anna', 'age': 54}\\n{'name': &quot;NK&quot;, 'age': 0}\\n</code></pre>\\n<p>I now want to read the text file into a list of dictionaries in the format</p>\\n<pre><code>[{'name':'Jack', 'age': 20}, {'name': 'Joseph', 'age': 13}, {'name':'anna', 'age': 54}, \\n{'name': &quot;NK&quot;, 'age': 0}]\\n</code></pre>\\n<p>So far, i used the below code</p>\\n<pre><code>val_cont_file = open('answers.txt', 'r')\\nf = val_cont_file.read()\\ntrain_answers = f.split(&quot;\\\\n&quot;)\\ntrain_answers = list(filter(None, train_answers))\\nval_cont_file.close()\\n</code></pre>\\n<p>and the output to this is</p>\\n<pre><code>[&quot;{'name':'Jack', 'age': 20}&quot;, &quot;{'name': 'Joseph', 'age': 13}&quot;, &quot;{'name':'anna', 'age': \\n54}&quot;, '{\\\\'name\\\\': &quot;NK&quot;, \\\\'age\\\\': 0}']\\n</code></pre>\\n<p>which is far from what i would want. How can i produce the desired output, I appreciate for the time and help</p>\",\n          \"find MAX,MIN and AVG of a set in Django<p>I have an object called <em>meter</em> and it has a set called <em>powerConsumptionReport_set</em>.</p>\\n<p>This is the models.py :</p>\\n<pre><code>class Meter(models.Model):\\nregion                  = models.PositiveSmallIntegerField(null=1)\\nIPAddress               = models.GenericIPAddressField(default=0,null=False,blank=False,unique=True)\\nPortNumber              = models.IntegerField(default=1024)\\nSerialNumber            = models.IntegerField(default=00000000,null=False,blank=False,unique=True)\\n\\nclass PowerConsumptionReport(models.Model):\\nmeter = models.ForeignKey(Meter, blank=True, null=True, on_delete=models.CASCADE)\\npower = models.FloatField()\\n</code></pre>\\n<p>I need to find Max value of <em>power</em> field from the <em>powerConsumptionReport_set</em> and display it in my template.</p>\\n<p>This is the DetailView i used to show each Meter :</p>\\n<pre><code>class MeterDetailView(DetailView):\\nmodel = Meter\\ntemplate_name = 'meter/specificMeter.html'\\n</code></pre>\\n<p>And the template is here:</p>\\n<pre><code>&lt;h1&gt;\\n*** here i want to show min value of the set **** - \\n{{ meter.powerconsumptionreport_set.first.power }} \\n&lt;/h1&gt;\\n</code></pre>\\n<p>how can i access Max,Min and AVG value of <strong>power</strong> field from the powerConsumptionReport_set related to each meter.</p>\\n<p>Cheers.</p>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"<p>Long story short you cannot, the best thing you can do is send an embed With the URL.</p>\\n<pre class=\\\"lang-py prettyprint-override\\\"><code>@client.command()\\nasync def open(ctx, pagelink):\\n    page = pagelink\\n    if pagelink == 'yt':\\n        page = ('https://www.youtube.com/')\\n    elif pagelink == 'reddit':\\n        page = (&quot;https://www.reddit.com/&quot;)\\n    elif pagelink == &quot;whatsapp&quot;:\\n        page = (&quot;https://web.whatsapp.com/&quot;)\\n        \\n    embed=discord.Embed(title=&quot;Your link&quot;, url=page)\\n    await ctx.send(embed=embed)\\n</code></pre>\",\n          \"<p>This is one approach using <code>ast</code> module</p>\\n<p><strong>Ex:</strong></p>\\n<pre><code>import ast\\n\\nwith open('answers.txt', 'r') as infile:\\n    result = [ast.literal_eval(line) for line in infile if line.strip()]\\n</code></pre>\",\n          \"<p>Maybe getting these values in views.py is better than doing it in a template.\\nYou can achieve this:</p>\\n<pre><code>PowerConsumptionReport.objects.all().aggregate(Avg('power '))\\nPowerConsumptionReport.objects.all().aggregate(Min('power '))\\nPowerConsumptionReport.objects.all().aggregate(Max('power '))\\n</code></pre>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Adding Instructions**\n",
        "\n",
        "* Instructions for LLMs have been shown to improve model performance and generalization to unseen tasks (Google, 2022).\n",
        "* Wihtout the instruction, it is only question and answer. Model might not understand what to do.\n",
        "* With the instructions, the model gets a guideline as to what task to perform."
      ],
      "metadata": {
        "id": "sF1Pj2d64mP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INSTRUCTION_TEMPLATE = f\"\"\"\\\n",
        "Please answer the following Stackoverflow question on Python. \\\n",
        "Answer it like you are a developer answering Stackoverflow questions.\n",
        "â€‹\n",
        "Stackoverflow question:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pr9Rcnox4s5i"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A new column will combine INSTRUCTION_TEMPLATE and the question input_text.\n",
        "This avoids overwritting of any existing column which might be needed."
      ],
      "metadata": {
        "id": "R6cvU5Kp4xTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stack_overflow_df['input_text_instruct'] = INSTRUCTION_TEMPLATE + ' '\\\n",
        "    + stack_overflow_df['input_text']"
      ],
      "metadata": {
        "id": "VMk7raW2412B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset for Tuning**\n",
        "\n",
        "* Divide the data into a training and evaluation. By default, 80/20 split is used.\n",
        "* This (80/20 split) allows for more data to be used for tuning. The evaluation split is used as unseen data during tuning to evaluate performance.\n",
        "* The random_state parameter is used to ensure random sampling for a fair comparison."
      ],
      "metadata": {
        "id": "_Z9g49Qe43h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, evaluation = train_test_split(\n",
        "    stack_overflow_df,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "AeBJoaSB49Tr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Different Datasets and Flow**\n",
        "\n",
        "* Versioning data is important.\n",
        "* It allows for reproducibility, traceability, and maintainability of machine learning models.\n",
        "* Get the timestamp."
      ],
      "metadata": {
        "id": "zFnCK3tX4-xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "date = datetime.datetime.now().strftime(\"%H:%d:%m:%Y\")"
      ],
      "metadata": {
        "id": "tPhaJj2B5FLN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate a jsonl file.\n",
        "Name it as tune_data_stack_overflow_python_qa-{date}"
      ],
      "metadata": {
        "id": "Ts2nwMsF5HHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['input_text_instruct','output_text']\n",
        "tune_jsonl = train[cols].to_json(orient=\"records\", lines=True)"
      ],
      "metadata": {
        "id": "sO7PkH6X5P6R"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_filename = f\"tune_data_stack_overflow_\\\n",
        "                            python_qa-{date}.jsonl\""
      ],
      "metadata": {
        "id": "DlXKAv5L5Q9X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(training_data_filename, \"w\") as f:\n",
        "    f.write(tune_jsonl)"
      ],
      "metadata": {
        "id": "zXx8uh0D5Sm5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **For Evaluation Set**\n",
        "\n",
        "The code above generted a jsonl file for the train set. Now, make the evaluation set, which you can name as tune_eval_data_stack_overflow_python_qa-{date}.jsonl."
      ],
      "metadata": {
        "id": "jXMWLyA05gSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['input_text_instruct','output_text']\n",
        "\n",
        "### you need to use the \"evaluation\" set now\n",
        "tune_jsonl = evaluation[cols].to_json(orient=\"records\", lines=True)\n",
        "\n",
        "### change the file name\n",
        "evaluation_data_filename = f\"tune_eval_data_stack_overflow_\\\n",
        "                            python_qa-{date}.jsonl\"\n",
        "\n",
        "### write the file\n",
        "with open(evaluation_data_filename, \"w\") as f:\n",
        "    f.write(tune_jsonl)"
      ],
      "metadata": {
        "id": "vzakDWVm5f0m"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YDFas-bSQsPY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: Automation & Orchestration with Pipelines**"
      ],
      "metadata": {
        "id": "ZaGvcyGoRkag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup Kubeflow**\n",
        "\n",
        "We will use Kubeflow Pipelines to orchestrat and automate a workflow. Kubeflow Pipelines is an open source framework. It's like a construction kit for building machine learning pipelines, making it easy to orchestrate and automate complex tasks."
      ],
      "metadata": {
        "id": "nD3GjFHWwkJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import kfp\n",
        "  from kfp import local, dsl, compiler\n",
        "except:\n",
        "  !pip install kfp\n",
        "  import kfp\n",
        "  from kfp import local, dsl, compiler"
      ],
      "metadata": {
        "id": "rGylN0Kpw1nS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore FutureWarnings in kfp\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",\n",
        "                        category=FutureWarning,\n",
        "                        module='kfp.*')"
      ],
      "metadata": {
        "id": "KeisEwDyw45R"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kubeflow Pipelines**\n",
        "\n",
        "* Kubeflow pipelines consist of two key concepts: Components and pipelines\n",
        "* Pipeline components are like self-contained sets of code that perform various steps in your ML workflow, such as, the first step could be preprocessing data, and second step could be training a model."
      ],
      "metadata": {
        "id": "XRkBu2v9w6qF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Simple Pipeline Example**\n"
      ],
      "metadata": {
        "id": "nV_2PVWDxQym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Component 1\n",
        "@dsl.component\n",
        "def say_hello(name: str) -> str:\n",
        "    hello_text = f'Hello, {name}!'\n",
        "    return hello_text"
      ],
      "metadata": {
        "id": "GYdzOZ3zxYF3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we \"wrapped\" this say_hello function in the decorator @dsl.component, the function will not actually return a string.\n",
        "The function will return a PipelineTask object."
      ],
      "metadata": {
        "id": "lT2FbEcMxaZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local.init(runner=local.SubprocessRunner(use_venv=False))"
      ],
      "metadata": {
        "id": "nwNymXpB5-r6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hello_task = say_hello(name=\"Erwin\")\n",
        "print(hello_task, hello_task.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VefLk-vaxfSE",
        "outputId": "dd40c1db-f2c4-4877-daea-ceed2cf9b5cc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10:47:03.872 - INFO - Executing task \u001b[96m'say-hello'\u001b[0m\n",
            "10:47:03.874 - INFO - Streamed logs:\n",
            "\n",
            "    [KFP Executor 2024-10-16 10:47:04,631 INFO]: Looking for component `say_hello` in --component_module_path `/tmp/tmp.vSNvqhsMmT/ephemeral_component.py`\n",
            "    [KFP Executor 2024-10-16 10:47:04,631 INFO]: Loading KFP component \"say_hello\" from /tmp/tmp.vSNvqhsMmT/ephemeral_component.py (directory \"/tmp/tmp.vSNvqhsMmT\" and module name \"ephemeral_component\")\n",
            "    [KFP Executor 2024-10-16 10:47:04,632 INFO]: Got executor_input:\n",
            "    {\n",
            "        \"inputs\": {\n",
            "            \"parameterValues\": {\n",
            "                \"name\": \"Erwin\"\n",
            "            }\n",
            "        },\n",
            "        \"outputs\": {\n",
            "            \"parameters\": {\n",
            "                \"Output\": {\n",
            "                    \"outputFile\": \"/content/local_outputs/say-hello-2024-10-16-10-47-03-870034/say-hello/Output\"\n",
            "                }\n",
            "            },\n",
            "            \"outputFile\": \"/content/local_outputs/say-hello-2024-10-16-10-47-03-870034/say-hello/executor_output.json\"\n",
            "        }\n",
            "    }\n",
            "    [KFP Executor 2024-10-16 10:47:04,633 INFO]: Wrote executor output file to /content/local_outputs/say-hello-2024-10-16-10-47-03-870034/say-hello/executor_output.json.\n",
            "    \n",
            "\n",
            "10:47:04.646 - INFO - Task \u001b[96m'say-hello'\u001b[0m finished with status \u001b[92mSUCCESS\u001b[0m\n",
            "10:47:04.648 - INFO - Task \u001b[96m'say-hello'\u001b[0m outputs:\n",
            "    Output: 'Hello, Erwin!'\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<kfp.dsl.pipeline_task.PipelineTask object at 0x7e2b9df32bf0> Hello, Erwin!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The object that we'll use to pass the information in hello_text to other components in the pipeline is PipelineTask.output.\n",
        "\n",
        "Note when passing in values to the a dsl.component function, you have to specify the argument names (keyword arguments), and can't use positional arguments."
      ],
      "metadata": {
        "id": "GNPFNmtJxi1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this will give an error and ask you to specify the parameter name\n",
        "try:\n",
        "  hello_task = say_hello(\"Erwin\")\n",
        "except Exception as e:\n",
        "  print(\"Just kidding, sorry :P\\nHere's the error: \", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aJE4TizyCvH",
        "outputId": "e68676af-f4b7-4349-8bea-ca3573da5f66"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Just kidding, sorry :P\n",
            "Here's the error:  Components must be instantiated using keyword arguments. Positional parameters are not allowed (found 1 such parameters for component \"say-hello\").\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second component is dependent on the first component.\n",
        "Take the output of the first component and pass it to the second component."
      ],
      "metadata": {
        "id": "QBUcxFFayP1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Component 2\n",
        "@dsl.component\n",
        "def how_are_you(hello_text: str) -> str:\n",
        "    how_are_you = f\"{hello_text}. How are you?\"\n",
        "    return how_are_you"
      ],
      "metadata": {
        "id": "TNxBwsEhyXLj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that when we pass in the return value from the say_hello function, we want to pass in the PipelineTask.output object, and not the PipelineTask object itself."
      ],
      "metadata": {
        "id": "CD-kTuqoyc-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "how_task = how_are_you(hello_text=hello_task.output)\n",
        "print(how_task, how_task.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu1wXemXyg6m",
        "outputId": "b67b8841-eccb-4df5-a8fe-2295f37120f0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10:47:32.108 - INFO - Executing task \u001b[96m'how-are-you'\u001b[0m\n",
            "10:47:32.111 - INFO - Streamed logs:\n",
            "\n",
            "    [KFP Executor 2024-10-16 10:47:32,823 INFO]: Looking for component `how_are_you` in --component_module_path `/tmp/tmp.g2VxpQzvKg/ephemeral_component.py`\n",
            "    [KFP Executor 2024-10-16 10:47:32,823 INFO]: Loading KFP component \"how_are_you\" from /tmp/tmp.g2VxpQzvKg/ephemeral_component.py (directory \"/tmp/tmp.g2VxpQzvKg\" and module name \"ephemeral_component\")\n",
            "    [KFP Executor 2024-10-16 10:47:32,824 INFO]: Got executor_input:\n",
            "    {\n",
            "        \"inputs\": {\n",
            "            \"parameterValues\": {\n",
            "                \"hello_text\": \"Hello, Erwin!\"\n",
            "            }\n",
            "        },\n",
            "        \"outputs\": {\n",
            "            \"parameters\": {\n",
            "                \"Output\": {\n",
            "                    \"outputFile\": \"/content/local_outputs/how-are-you-2024-10-16-10-47-32-106764/how-are-you/Output\"\n",
            "                }\n",
            "            },\n",
            "            \"outputFile\": \"/content/local_outputs/how-are-you-2024-10-16-10-47-32-106764/how-are-you/executor_output.json\"\n",
            "        }\n",
            "    }\n",
            "    [KFP Executor 2024-10-16 10:47:32,824 INFO]: Wrote executor output file to /content/local_outputs/how-are-you-2024-10-16-10-47-32-106764/how-are-you/executor_output.json.\n",
            "    \n",
            "\n",
            "10:47:32.838 - INFO - Task \u001b[96m'how-are-you'\u001b[0m finished with status \u001b[92mSUCCESS\u001b[0m\n",
            "10:47:32.839 - INFO - Task \u001b[96m'how-are-you'\u001b[0m outputs:\n",
            "    Output: 'Hello, Erwin!. How are you?'\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<kfp.dsl.pipeline_task.PipelineTask object at 0x7e2b9df33fa0> Hello, Erwin!. How are you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will give an error and ask you to pass in a built-in data type\n",
        "try:\n",
        "  how_task = how_are_you(hello_text=hello_task)\n",
        "  print(how_task, how_task.output)\n",
        "except Exception as e:\n",
        "  print(\"Just kidding, sorry :P\\nHere's the error: \", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFsd6qFcynKo",
        "outputId": "507d9b61-e4ad-4617-f618-97d6e316404d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Just kidding, sorry :P\n",
            "Here's the error:  Constant argument inputs must be one of type ['String', 'Integer', 'Float', 'Boolean', 'List', 'Dict'] Got: <kfp.dsl.pipeline_task.PipelineTask object at 0x7e2b9df32bf0> of type <class 'kfp.dsl.pipeline_task.PipelineTask'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the pipeline**\n",
        "\n",
        "Notice how the input to say_hello is just recipient, since that is already a built-in data type (a String).\n",
        "Recall that to get the value from a PipelineTask object, you'll use PipelineTask.output to pass in that value to another Pipeline Component function.\n",
        "Notice that Pipeline function should return the PipelineTask.output as well."
      ],
      "metadata": {
        "id": "Z4OoOk6nzeTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Pipeline\n",
        "@dsl.pipeline\n",
        "def hello_pipeline(recipient: str) -> str:\n",
        "    hello_task = say_hello(name=recipient)\n",
        "    how_task = how_are_you(hello_text=hello_task.output)\n",
        "    return how_task.output"
      ],
      "metadata": {
        "id": "o7RRn8VDztoQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_output = hello_pipeline(recipient=\"Erwin\")\n",
        "print(pipeline_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZp-mIJmz-Ly",
        "outputId": "1d88fa18-8b2f-4cf3-8e62-26745fd61234"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10:47:47.628 - INFO - Running pipeline: \u001b[95m'hello-pipeline'\u001b[0m\n",
            "----------------------------------------------------------------------------------------------------\n",
            "10:47:47.631 - INFO - Executing task \u001b[96m'say-hello'\u001b[0m\n",
            "10:47:47.633 - INFO - Streamed logs:\n",
            "\n",
            "    [KFP Executor 2024-10-16 10:47:48,332 INFO]: Looking for component `say_hello` in --component_module_path `/tmp/tmp.wBXnKSYlru/ephemeral_component.py`\n",
            "    [KFP Executor 2024-10-16 10:47:48,332 INFO]: Loading KFP component \"say_hello\" from /tmp/tmp.wBXnKSYlru/ephemeral_component.py (directory \"/tmp/tmp.wBXnKSYlru\" and module name \"ephemeral_component\")\n",
            "    [KFP Executor 2024-10-16 10:47:48,333 INFO]: Got executor_input:\n",
            "    {\n",
            "        \"inputs\": {\n",
            "            \"parameterValues\": {\n",
            "                \"name\": \"Erwin\"\n",
            "            }\n",
            "        },\n",
            "        \"outputs\": {\n",
            "            \"parameters\": {\n",
            "                \"Output\": {\n",
            "                    \"outputFile\": \"/content/local_outputs/hello-pipeline-2024-10-16-10-47-47-627716/say-hello/Output\"\n",
            "                }\n",
            "            },\n",
            "            \"outputFile\": \"/content/local_outputs/hello-pipeline-2024-10-16-10-47-47-627716/say-hello/executor_output.json\"\n",
            "        }\n",
            "    }\n",
            "    [KFP Executor 2024-10-16 10:47:48,333 INFO]: Wrote executor output file to /content/local_outputs/hello-pipeline-2024-10-16-10-47-47-627716/say-hello/executor_output.json.\n",
            "    \n",
            "\n",
            "10:47:48.347 - INFO - Task \u001b[96m'say-hello'\u001b[0m finished with status \u001b[92mSUCCESS\u001b[0m\n",
            "10:47:48.348 - INFO - Task \u001b[96m'say-hello'\u001b[0m outputs:\n",
            "    Output: 'Hello, Erwin!'\n",
            "----------------------------------------------------------------------------------------------------\n",
            "10:47:48.350 - INFO - Executing task \u001b[96m'how-are-you'\u001b[0m\n",
            "10:47:48.351 - INFO - Streamed logs:\n",
            "\n",
            "    [KFP Executor 2024-10-16 10:47:49,069 INFO]: Looking for component `how_are_you` in --component_module_path `/tmp/tmp.oufTSoj3Em/ephemeral_component.py`\n",
            "    [KFP Executor 2024-10-16 10:47:49,069 INFO]: Loading KFP component \"how_are_you\" from /tmp/tmp.oufTSoj3Em/ephemeral_component.py (directory \"/tmp/tmp.oufTSoj3Em\" and module name \"ephemeral_component\")\n",
            "    [KFP Executor 2024-10-16 10:47:49,069 INFO]: Got executor_input:\n",
            "    {\n",
            "        \"inputs\": {\n",
            "            \"parameterValues\": {\n",
            "                \"hello_text\": \"Hello, Erwin!\"\n",
            "            }\n",
            "        },\n",
            "        \"outputs\": {\n",
            "            \"parameters\": {\n",
            "                \"Output\": {\n",
            "                    \"outputFile\": \"/content/local_outputs/hello-pipeline-2024-10-16-10-47-47-627716/how-are-you/Output\"\n",
            "                }\n",
            "            },\n",
            "            \"outputFile\": \"/content/local_outputs/hello-pipeline-2024-10-16-10-47-47-627716/how-are-you/executor_output.json\"\n",
            "        }\n",
            "    }\n",
            "    [KFP Executor 2024-10-16 10:47:49,070 INFO]: Wrote executor output file to /content/local_outputs/hello-pipeline-2024-10-16-10-47-47-627716/how-are-you/executor_output.json.\n",
            "    \n",
            "\n",
            "10:47:49.084 - INFO - Task \u001b[96m'how-are-you'\u001b[0m finished with status \u001b[92mSUCCESS\u001b[0m\n",
            "10:47:49.086 - INFO - Task \u001b[96m'how-are-you'\u001b[0m outputs:\n",
            "    Output: 'Hello, Erwin!. How are you?'\n",
            "----------------------------------------------------------------------------------------------------\n",
            "10:47:49.087 - INFO - Pipeline \u001b[95m'hello-pipeline'\u001b[0m finished with status \u001b[92mSUCCESS\u001b[0m\n",
            "<kfp.dsl.pipeline_task.PipelineTask object at 0x7e2b9df33790>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that if you tried to return a PipelineTask object instead of the PipelineTask.output, you'd get an error message"
      ],
      "metadata": {
        "id": "Avc38DNO0CyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Pipeline with wrong return value type\n",
        "\n",
        "# @dsl.pipeline\n",
        "# def hello_pipeline_with_error(recipient: str) -> str:\n",
        "#     hello_task = say_hello(name=recipient)\n",
        "#     how_task = how_are_you(hello_text=hello_task.output)\n",
        "#     return how_task\n",
        "\n",
        "    # returning the PipelineTask object itself will give you an error"
      ],
      "metadata": {
        "id": "q25Y0xsK0J-Q"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement the pipeline**\n",
        "\n",
        "* A pipeline is a set of components that you orchestrate.\n",
        "* It lets you define the order of execution and how data flows from one step to another.\n",
        "* Compile the pipeline into a yaml file, pipeline.yaml\n",
        "* You can look at the pipeline.yaml file in your workspace by running the cat command or simply going and opening the file directly."
      ],
      "metadata": {
        "id": "kQybXYtm0Qk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiler.Compiler().compile(hello_pipeline, 'pipeline.yaml')"
      ],
      "metadata": {
        "id": "wGmcNDBD0M_i"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the arguments, the input that goes into the pipeline."
      ],
      "metadata": {
        "id": "Cnpj2OtE0_fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_arguments = {\n",
        "    \"recipient\": \"World!\",\n",
        "}"
      ],
      "metadata": {
        "id": "Q4k6Ig5_0_Iu"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the pipeline.yaml\n",
        "!cat pipeline.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo1Q4N3e1Fb1",
        "outputId": "ad506bb1-0a58-40c9-daf8-df8d08a483b4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# PIPELINE DEFINITION\n",
            "# Name: hello-pipeline\n",
            "# Inputs:\n",
            "#    recipient: str\n",
            "# Outputs:\n",
            "#    Output: str\n",
            "components:\n",
            "  comp-how-are-you:\n",
            "    executorLabel: exec-how-are-you\n",
            "    inputDefinitions:\n",
            "      parameters:\n",
            "        hello_text:\n",
            "          parameterType: STRING\n",
            "    outputDefinitions:\n",
            "      parameters:\n",
            "        Output:\n",
            "          parameterType: STRING\n",
            "  comp-say-hello:\n",
            "    executorLabel: exec-say-hello\n",
            "    inputDefinitions:\n",
            "      parameters:\n",
            "        name:\n",
            "          parameterType: STRING\n",
            "    outputDefinitions:\n",
            "      parameters:\n",
            "        Output:\n",
            "          parameterType: STRING\n",
            "deploymentSpec:\n",
            "  executors:\n",
            "    exec-how-are-you:\n",
            "      container:\n",
            "        args:\n",
            "        - --executor_input\n",
            "        - '{{$}}'\n",
            "        - --function_to_execute\n",
            "        - how_are_you\n",
            "        command:\n",
            "        - sh\n",
            "        - -c\n",
            "        - \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip ||\\\n",
            "          \\ python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1\\\n",
            "          \\ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.9.0'\\\n",
            "          \\ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\\\"3.9\\\"' && \\\"\\\n",
            "          $0\\\" \\\"$@\\\"\\n\"\n",
            "        - sh\n",
            "        - -ec\n",
            "        - 'program_path=$(mktemp -d)\n",
            "\n",
            "\n",
            "          printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "\n",
            "          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\n",
            "          '\n",
            "        - \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import\\\n",
            "          \\ *\\n\\ndef how_are_you(hello_text: str) -> str:\\n    how_are_you = f\\\"{hello_text}.\\\n",
            "          \\ How are you?\\\"\\n    return how_are_you\\n\\n\"\n",
            "        image: python:3.8\n",
            "    exec-say-hello:\n",
            "      container:\n",
            "        args:\n",
            "        - --executor_input\n",
            "        - '{{$}}'\n",
            "        - --function_to_execute\n",
            "        - say_hello\n",
            "        command:\n",
            "        - sh\n",
            "        - -c\n",
            "        - \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip ||\\\n",
            "          \\ python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1\\\n",
            "          \\ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.9.0'\\\n",
            "          \\ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\\\"3.9\\\"' && \\\"\\\n",
            "          $0\\\" \\\"$@\\\"\\n\"\n",
            "        - sh\n",
            "        - -ec\n",
            "        - 'program_path=$(mktemp -d)\n",
            "\n",
            "\n",
            "          printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "\n",
            "          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\n",
            "          '\n",
            "        - \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import\\\n",
            "          \\ *\\n\\ndef say_hello(name: str) -> str:\\n    hello_text = f'Hello, {name}!'\\n\\\n",
            "          \\    return hello_text\\n\\n\"\n",
            "        image: python:3.8\n",
            "pipelineInfo:\n",
            "  name: hello-pipeline\n",
            "root:\n",
            "  dag:\n",
            "    outputs:\n",
            "      parameters:\n",
            "        Output:\n",
            "          valueFromParameter:\n",
            "            outputParameterKey: Output\n",
            "            producerSubtask: how-are-you\n",
            "    tasks:\n",
            "      how-are-you:\n",
            "        cachingOptions:\n",
            "          enableCache: true\n",
            "        componentRef:\n",
            "          name: comp-how-are-you\n",
            "        dependentTasks:\n",
            "        - say-hello\n",
            "        inputs:\n",
            "          parameters:\n",
            "            hello_text:\n",
            "              taskOutputParameter:\n",
            "                outputParameterKey: Output\n",
            "                producerTask: say-hello\n",
            "        taskInfo:\n",
            "          name: how-are-you\n",
            "      say-hello:\n",
            "        cachingOptions:\n",
            "          enableCache: true\n",
            "        componentRef:\n",
            "          name: comp-say-hello\n",
            "        inputs:\n",
            "          parameters:\n",
            "            name:\n",
            "              componentInputParameter: recipient\n",
            "        taskInfo:\n",
            "          name: say-hello\n",
            "  inputDefinitions:\n",
            "    parameters:\n",
            "      recipient:\n",
            "        parameterType: STRING\n",
            "  outputDefinitions:\n",
            "    parameters:\n",
            "      Output:\n",
            "        parameterType: STRING\n",
            "schemaVersion: 2.1.0\n",
            "sdkVersion: kfp-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use Vertex AI pipelines, a managed, serverless environment, to execute the yaml files."
      ],
      "metadata": {
        "id": "jqzFUZ1z1NsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud.aiplatform import PipelineJob\n",
        "\n",
        "job = PipelineJob(\n",
        "        template_path=\"pipeline.yaml\",\n",
        "        display_name=f\"deep_learning_ai_pipeline\",\n",
        "        parameter_values=pipeline_arguments,\n",
        "        location=\"us-central1\",\n",
        "        pipeline_root=\"./\"\n",
        ")\n",
        "\n",
        "# submit for execution\n",
        "job.submit()\n",
        "\n",
        "# check to see the status of the job\n",
        "job.state"
      ],
      "metadata": {
        "id": "Q5O7QQRV1a-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Real-life Pipeline Example**\n",
        "\n",
        "* Automation and Orchestration of a Supervised Tuning Pipeline.\n",
        "* Reuse an existing Kubeflow Pipeline for Parameter-Efficient Fine-Tuning (PEFT) for a foundation model from Google, called PaLM 2.\n",
        "* Advantage of reusing a pipleline means you do not have to build it from scratch, you can only specify some of the parameters."
      ],
      "metadata": {
        "id": "QmBgZFnJ1gmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DATA_URI = \"./tune_data_stack_overflow_python_qa.jsonl\"\n",
        "EVAUATION_DATA_URI = \"./tune_eval_data_stack_overflow_python_qa.jsonl\""
      ],
      "metadata": {
        "id": "oNwRp2Y02FLg"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Provide the model with a version.\n",
        "* Versioning model allows for:\n",
        "  * Reproducibility: Reproduce your results and ensure your models perform as expected.\n",
        "  * Auditing: Track changes to your models.\n",
        "  * Rollbacks: Roll back to a previous version of your model."
      ],
      "metadata": {
        "id": "N7FusgZA2HP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path to the pipeline file to reuse\n",
        "template_path = 'https://us-kfp.pkg.dev/ml-pipeline/large-language-model-pipelines/tune-large-model/v2.0.0'"
      ],
      "metadata": {
        "id": "PMPK_HTm3S16"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "date = datetime.datetime.now().strftime(\"%H:%d:%m:%Y\")"
      ],
      "metadata": {
        "id": "N-k8wHAx3UTM"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = f\"deep-learning-ai-model-{date}\""
      ],
      "metadata": {
        "id": "Rh_cMl5aRmcO"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example uses two **PaLM** model parameters:\n",
        "1. **TRAINING_STEPS:** Number of training steps to use when tuning the model. For extractive QA you can set it from 100-500.\n",
        "2. **EVALUATION_INTERVAL:** The interval determines how frequently a trained model is evaluated against the created evaluation set to assess its performance and identify issues. Default will be 20, which means after every 20 training steps, the model is evaluated on the evaluation dataset.\n"
      ],
      "metadata": {
        "id": "07-kOv9S24KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_STEPS = 200\n",
        "EVALUATION_INTERVAL = 20"
      ],
      "metadata": {
        "id": "fSc8dnrD20jO"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Project ID and credentials\n",
        "from utils import authenticate\n",
        "credentials, PROJECT_ID = authenticate()\n",
        "REGION = \"us-central1\""
      ],
      "metadata": {
        "id": "KhSffGx32rtH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the arguments, the input that goes into the pipeline.\n",
        "pipeline_arguments = {\n",
        "    \"model_display_name\": MODEL_NAME,\n",
        "    \"location\": REGION,\n",
        "    \"large_model_reference\": \"text-bison@001\",\n",
        "    \"project\": PROJECT_ID,\n",
        "    \"train_steps\": TRAINING_STEPS,\n",
        "    \"dataset_uri\": TRAINING_DATA_URI,\n",
        "    \"evaluation_interval\": EVALUATION_INTERVAL,\n",
        "    \"evaluation_data_uri\": EVAUATION_DATA_URI,\n",
        "}"
      ],
      "metadata": {
        "id": "0fBKLlGm2kPZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job = PipelineJob(\n",
        "        template_path=template_path,\n",
        "        display_name=f\"deep_learning_ai_pipeline-{date}\",\n",
        "        parameter_values=pipeline_arguments,\n",
        "        location=REGION,\n",
        "        pipeline_root=\"./\",\n",
        "        enable_caching=True\n",
        ")\n",
        "\n",
        "# submit for execution\n",
        "job.submit()\n",
        "\n",
        "# check to see the status of the job\n",
        "job.state"
      ],
      "metadata": {
        "id": "AXFuO10L2fdl"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 3: Predictions, Prompts and Safety**"
      ],
      "metadata": {
        "id": "C8UNEd0ASZDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup and Initialization**"
      ],
      "metadata": {
        "id": "rsnqDynck5j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Project ID and credentials.\n",
        "\n",
        "from utils import authenticate\n",
        "credentials, PROJECT_ID = authenticate()\n",
        "REGION = \"us-central1\""
      ],
      "metadata": {
        "id": "R-SQJEFhhKd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Import the Vertex AI SDK.\n",
        "* Import and load the model.\n",
        "* Initialize it."
      ],
      "metadata": {
        "id": "eCrTMiolhSul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "vertexai.init(project = PROJECT_ID,\n",
        "              location = REGION,\n",
        "              credentials = credentials)"
      ],
      "metadata": {
        "id": "KI6DInW6hYzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Deployment**\n",
        "* Load Balancing\n",
        "* Load from pre-trained text-bison@001\n",
        "* Retrieve the endpoints (deployed as REST API)"
      ],
      "metadata": {
        "id": "07lM2_b9hgdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
      ],
      "metadata": {
        "id": "a29o3yXxhnoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Get the list of multiple models executed and deployed.\n",
        "* This helps to rout the traffic to different endpoints.\n"
      ],
      "metadata": {
        "id": "cFBIVCX2hoUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_tuned_models = model.list_tuned_model_names()\n",
        "for i in list_tuned_models:\n",
        "    print (i)"
      ],
      "metadata": {
        "id": "WbA8F7zthuav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomly select from one of the endpoints to divide the prediction load."
      ],
      "metadata": {
        "id": "JbO0kvbXh0C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "tuned_model_select = random.choice(list_tuned_models)"
      ],
      "metadata": {
        "id": "PC4sS3K0h2W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Getting the Response**\n",
        "* Load the endpoint of the randomly selected model to be called with a prompt.\n",
        "* The prompt needs to be as similar as possible as the one you trained your model on (python questions from stack overflow dataset)\n"
      ],
      "metadata": {
        "id": "lZ7IUf7Qh5Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployed_model = TextGenerationModel.get_tuned_model(tuned_model_select)"
      ],
      "metadata": {
        "id": "R2vLy7rmiBOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use deployed_model.predit to call the API using the prompt."
      ],
      "metadata": {
        "id": "eZhO2eXxiFuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = \"How can I load a csv file using Pandas?\"\n",
        "response = deployed_model.predict(PROMPT)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "yRN-wIiRiNlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pprint makes the response easily readable.\n",
        "\n",
        "Sending multiple prompts can return multiple responses ([0], [1], [2]...)\n",
        "In this example, only 1 prompt is being sent, and returning only 1 response ([0])"
      ],
      "metadata": {
        "id": "MZ_rcO5SiSec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "NVhRjPz3iVSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the first object of the response\n",
        "output1 = response._prediction_response[0]\n",
        "\n",
        "# load the second object of the response\n",
        "output2 = response._prediction_response[0][0]\n",
        "\n",
        "# retrieve the \"content\" key from the second object\n",
        "final_output = response._prediction_response[0][0][\"content\"]\n",
        "\n",
        "# printing \"content\" key from the second object\n",
        "print(final_output)"
      ],
      "metadata": {
        "id": "DtReO1ykiilf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prompt Management and Templates**\n",
        "* Remember that the model was trained on data that had an Instruction and a Question as a Prompt.\n",
        "* In the example above, only a Question as a Prompt was used for a response.\n",
        "* It is important for the production data to be the same as the training data. Difference in data can effect the model performance.\n",
        "* Add the same Instruction as it was used for training data, and combine it with a Question to be used as a Prompt.\n"
      ],
      "metadata": {
        "id": "7GJ2PIYCiwLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INSTRUCTION = \"\"\"\\\n",
        "Please answer the following Stackoverflow question on Python.\\\n",
        "Answer it like\\\n",
        "you are a developer answering Stackoverflow questions.\\\n",
        "Question:\n",
        "\"\"\"\n",
        "\n",
        "QUESTION = \"How can I store my TensorFlow checkpoint on\\\n",
        "Google Cloud Storage? Python example?\""
      ],
      "metadata": {
        "id": "Os4L_OlXi-7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the intruction and the question to create the prompt.\n",
        "\n",
        "PROMPT = f\"\"\"\n",
        "{INSTRUCTION} {QUESTION}\n",
        "\"\"\"\n",
        "\n",
        "print(PROMPT)"
      ],
      "metadata": {
        "id": "bq4Rls54jXro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the response using the new prompt, which is consistent with the prompt used for training.\n",
        "\n",
        "final_response = deployed_model.predict(PROMPT)\n",
        "output = final_response._prediction_response[0][0][\"content\"]\n",
        "print(output)   # Note how the response changed from earlier."
      ],
      "metadata": {
        "id": "eq9qWoVOjdYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Safety Attributes**\n",
        "* The reponse also includes safety scores.\n",
        "* These scores can be used to make sure that the LLM's response is within the boundries of the expected behaviour.\n",
        "* The first layer for this check, blocked, is by the model itself."
      ],
      "metadata": {
        "id": "EA1WkwyqjqWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blocked = response._prediction_response[0][0]['safetyAttributes']['blocked']\n",
        "print(blocked)"
      ],
      "metadata": {
        "id": "3xDn2izxj2kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The second layer of this check can be defined by you, as a practitioner, according to the thresholds you set.\n",
        "* The response returns probabilities for each safety score category which can be used to design the thresholds."
      ],
      "metadata": {
        "id": "K5Xy0urOkA5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the \"safetyAttributes\" of the response\n",
        "safety_attributes = response._prediction_response[0][0]['safetyAttributes']\n",
        "pprint(safety_attributes)"
      ],
      "metadata": {
        "id": "_lXMhfiIkWqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Citations**\n",
        "* Ideally, a LLM should generate as much original cotent as possible.\n",
        "* The citationMetadata can be used to check and reduce the chances of a LLM generating a lot of existing content."
      ],
      "metadata": {
        "id": "7OUD8Q0-kfx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "citation = response._prediction_response[0][0]['citationMetadata']['citations']\n",
        "pprint(citation)"
      ],
      "metadata": {
        "id": "aTD3tb-fkoBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = \"Finish the sentence: To be, or not \"\n",
        "response = deployed_model.predict(PROMPT)"
      ],
      "metadata": {
        "id": "Rw1vWle3kMNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output of the model\n",
        "output = response._prediction_response[0][0][\"content\"]\n",
        "print(output)"
      ],
      "metadata": {
        "id": "gkNyUvn0kJqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for citation\n",
        "citation = response._prediction_response[0][0]['citationMetadata']['citations']\n",
        "pprint(citation)"
      ],
      "metadata": {
        "id": "XhYxb7bukF7G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}